---
sidebar_position: 4
---

# Build GStreamer pipeline with opencv-python 

This tutorial demonstrates how to use OpenCV with GStreamer to capture video from cameras. It supports different camera configurations, pixel formats, and frame size.

## Tutorial

### Prerequisites
1. opencv-python with gstreamer backend
2. **windows**:  
  Install the C++ version of sensing-dev with `-InstallGstPlugins`. Make sure GST_PLUGIN_PATH is set.
3. **linux**:  
  Install the C++ version of sensing-dev with `--install-gst-tools`. Set the GST_PLUGIN_PATH environment variable and sensing-dev library_path:
  ```bash
  export GST_PLUGIN_PATH=/opt/sensing-dev/lib/x86_64-linux-gnu/gstreamer-1.0
  export LD_LIBRARY_PATH=/opt/sensing-dev/lib:/opt/sensing-dev/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
  ```

### Configuration
Please adjust the camera_name, pixelformat, width, height, framerate based on your requirements
```python
  camera_name = 'replace-by-your-camera-name'
  pixelformat = 'Mono8'
    # pixelformat = 'BayerBG8'
  width = 1920
  height = 1080
  framerate = 60
```

### Build a pipeline

The pipeline starts with aravissrc, which connects to the camera.
The camera-name parameter specifies which camera to use.
#### Frame Processing:

##### For color images in Bayer format:
1. Convert the Bayer format to RGB using `bayer2rgb`.
2. Adjust the image format using `videoconvert` to ensure compatibility with OpenCV.

##### For grayscale images:
1. Support raw formats such as `GRAY8` (8-bit) or `GRAY16_LE` (16-bit).
2. Adjust the image format using `videoconvert`.

#### Output to OpenCV:

The final stage is appsink, which allows OpenCV to access the processed video frames.

##### Example Pipelines:
1. Color (Bayer)(8-bit):

```
aravissrc camera-name="<camera-name>" ! gendcseparator ! queue ! video/x-bayer,format=bggr,width=1920,height=1080,framerate=60/1 ! bayer2rgb ! videoconvert ! appsink
```

2. Grayscale (8-bit)

```
aravissrc camera-name="<camera-name>" ! gendcseparator ! queue ! video/x-raw,format=GRAY8,width=1920,height=1080,framerate=60/1 ! videoconvert ! appsink
```

3. Grayscale (16-bit):

```
aravissrc camera-name="<camera-name>" ! gendcseparator ! queue ! video/x-raw,format=GRAY16_LE,width=1920,height=1080,framerate=60/1 ! videoconvert ! appsink
```

The line `cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)` connects OpenCV to the GStreamer Pipeline and tells OpenCV to use the pipeline to capture video frames.

:::note
currently this tutorial does not support BayerBG10 and BayerBG12, since for gstreamer 1.20.3, bayer2rgb only support 8 bits.
:::

### Display with OpenCV

`outputs` is the `List` having 2 buffers. Each buffer is stored into numpy array, and we can access it by index (`output_datas[i]`).
```python
while (user_input == -1):
    ret, frame = cap.read()
    if not ret:
        print("Can't receive frame")
        break
    cv2.imshow('opencv with gstreamer test', frame)
    user_input = cv2.waitKeyEx(1)

```
Do not forget to destroy windows and release the camera after `for` loop.

```python
cv2.destroyAllWindows()
cap.release()
```
## Complete code

import {tutorial_version} from "@site/static/version_const/latest.js"
import GenerateTutorialLink from '@site/static/tutorial_link.js';

<GenerateTutorialLink language="python" tag={tutorial_version} tutorialfile="gstreamer/tutorial1_display" />
