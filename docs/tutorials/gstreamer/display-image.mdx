---
sidebar_position: 4
---

# Display Image with Gstreamer

This tutorial demonstrates how to use OpenCV with GStreamer, specifically leveraging the `appsink` element to capture and process video streams. 
While the GStreamer API allows you to build and run pipelines for video capture and processing, combining the `appsink` element with OpenCV enables you to retrieve the output of a GStreamer pipeline directly into OpenCV for further manipulation. 
This approach also supports various camera configurations, pixel formats, and frame sizes.

## Tutorial

### Prerequisites
1. opencv-python with gstreamer backend
2. **windows**:  
  Install the C++ version of sensing-dev with `-InstallGstPlugins`. Make sure `GST_PLUGIN_PATH` is set.
3. **linux**:  
  Install the C++ version of sensing-dev with `--install-gst-tools`. Set the `GST_PLUGIN_PATH` environment variable and sensing-dev library_path:
  ```bash
  export GST_PLUGIN_PATH=/opt/sensing-dev/lib/x86_64-linux-gnu/gstreamer-1.0
  export LD_LIBRARY_PATH=/opt/sensing-dev/lib:/opt/sensing-dev/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
  ```

### Configuration
Please adjust the camera_name, pixelformat, width, height, framerate based on your requirements.  You can obtain these values by [arv-tool-0.8](../../external/aravis/arv-tools.md) in Sensing-Dev software package

```python
  camera_name = 'replace-by-your-camera-name'
  pixelformat = 'Mono8'
    # pixelformat = 'BayerBG8'
  width = 1920
  height = 1080
  framerate = 60
```

### Build a pipeline

The pipeline starts with `aravissrc`, which connects to the camera.

The camera-name parameter specifies which camera to use.

#### Frame Processing:

##### For color images in Bayer format:
1. Convert the Bayer format to RGB using `bayer2rgb`.
2. Adjust the image format using `videoconvert` to ensure compatibility with OpenCV.

##### For grayscale images:
1. Support raw formats such as `GRAY8` (8-bit) or `GRAY16_LE` (16-bit).
2. Adjust the image format using `videoconvert`.

#### Output to OpenCV:

The final stage is `appsink`, which allows OpenCV to access the processed video frames.

##### Example Pipelines:
1. Color (Bayer)(8-bit):

```
aravissrc camera-name="<camera-name>" ! gendcseparator ! queue ! video/x-bayer,format=bggr,width=1920,height=1080,framerate=60/1 ! bayer2rgb ! videoconvert ! appsink
```

2. Grayscale (8-bit)

```
aravissrc camera-name="<camera-name>" ! gendcseparator ! queue ! video/x-raw,format=GRAY8,width=1920,height=1080,framerate=60/1 ! videoconvert ! appsink
```

3. Grayscale (16-bit):

```
aravissrc camera-name="<camera-name>" ! gendcseparator ! queue ! video/x-raw,format=GRAY16_LE,width=1920,height=1080,framerate=60/1 ! videoconvert ! appsink
```

The line `cap = cv2.VideoCapture(pipeline, cv2.CAP_GSTREAMER)` connects OpenCV to the GStreamer Pipeline and tells OpenCV to use the pipeline to capture video frames.

:::note
Currently this tutorial does not support BayerBG10 and BayerBG12, since for gstreamer 1.20.3, bayer2rgb only support 8 bits.
:::

### Display with OpenCV

The output of `cap.read()` are `ret` and `frame` which are the result of reading the capture data and its data itself respectively.

By displaying `frame` per pipeline execution with `for` loop, it looks like the sequential images.

```python
while (user_input == -1):
    ret, frame = cap.read()
    if not ret:
        print("Can't receive frame")
        break
    cv2.imshow('opencv with gstreamer test', frame)
    user_input = cv2.waitKeyEx(1)

```
Do not forget to destroy windows and release the camera after `for` loop.

```python
cv2.destroyAllWindows()
cap.release()
```
## Complete code

import {tutorial_version} from "@site/static/version_const/latest.js"
import GenerateTutorialLink from '@site/static/tutorial_link.js';

<GenerateTutorialLink language="gstreamer" tag={tutorial_version} tutorialfile="tutorial1_display" />
